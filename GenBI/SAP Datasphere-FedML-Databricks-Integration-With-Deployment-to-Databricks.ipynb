{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d4428c7-a2b8-4279-8d37-7a719dd95c50",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Sample notebook showing end-to-end Sales prediction use case using the FedML Databricks Library. \n",
    "\n",
    "### The FedML Databricks Library reads the training data via SAP Datasphere, trains the model in Databricks, deploys the model in Databricks and the inference result is written back to SAP Datasphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2c5ad33-783d-49e7-b11d-6ca46c80f3e7",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Install fedml_databricks library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "69eb7024-c0e5-4ba8-8abf-7b1c26a8a7cb",
     "showTitle": false,
     "title": ""
    },
    "gather": {
     "logged": 1633630686536
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install fedml-databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "52874bc5-2a3d-4d88-953a-f99d7932ee8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2f6f09c4-2360-4c7a-b081-32e1eba8c091",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pyspark.sql.functions import col\n",
    "from fedml_databricks import DbConnection, predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe8cb452-4540-4821-bf39-56a648acbf05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 1. Connect to SAP Datasphere, Explore, Acquire and Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4bf193f-6b54-415d-93dd-8e160a5826ad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.1 Connect to SAP Datasphere.\n",
    "\n",
    "Create a Databricks Secret Scope by referring the [(link)](https://docs.databricks.com/security/secrets/secret-scopes.html#create-a-databricks-backed-secret-scope). Then, create the Databricks Secret containing SAP Datasphere credentials in the form of json, using the [(link)](https://docs.databricks.com/security/secrets/secrets.html#create-a-secret-in-a-databricks-backed-scope). The  SAP Datasphere connection credentials can be obtained by completing the pre-requisite step using the [(link)](https://github.com/SAP-samples/data-warehouse-cloud-fedml/blob/main/Databricks/docs/dbconnection.md#pre-requisite#pre-requisite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8ac67fd-7fb8-4d8f-b06a-78f50004b997",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "config_json={\n",
    "    \"address\":  \"985639e9-cd50-4b52-8832-f4e244263077.hana.prod-us10.hanacloud.ondemand.com\",\n",
    "    \"port\": \"443\",\n",
    "    \"user\": \"ROWE#SQL\",\n",
    "    \"password\": \"@8iUTlZey]QyE^2A51RY-]QN^>FrM*IA\",\n",
    "    \"schema\": \"ROWE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f259a783-fe8a-41b0-814f-98d38bfa7f01",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "db = DbConnection(dict_obj=config_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c20e602b-aaab-425c-b779-90bf9fa6a3de",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.2 List all business models available to read from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdacc685-6a4f-4083-a4c7-9c2591c30832",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data= db.get_schema_views()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61c01e32-ed4b-4792-aebd-c278dd1ab4bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.3 Query the SAP Datasphere data using SQL Queries. Get the data as a PySpark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d76d0172-5724-4a9b-af07-faa609465d1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df=db.execute_query_pyspark('SELECT * FROM \\\"ROWE\\\".\\\"Sales_Orders\"')\n",
    "spark_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cab7a39e-186e-4ec2-9160-3c2534106bf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "##spark_df=db.execute_query_pyspark('SELECT * FROM \\\"DEMOSALESANALYSIS\\\".\\\"PP_Gross_Sales_S4\\\"')\n",
    "##spark_df.show(truncate=False)\n",
    "\n",
    "spark_df = spark_df.withColumn(\"Year\", col('SALESDOCUMENTDATE').substr(1, 4))\n",
    "\n",
    "spark_df.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "526282ff-d6ac-4baf-9454-105df3aa9041",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 1.3.1 Get Insights from the data. In the below cell, we get the average net amount for the year '2021'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fee7a22c-7737-433e-aafc-fae98b2d973b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "average_sales_for_2021_df=spark_df.filter(spark_df['Year']=='2021').groupBy().avg('NETAMOUNT')\n",
    "average_sales_for_2021_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62c357b4-fdf7-4b9b-89c1-56520f6d1b80",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 1.3.2 Convert the PySpark DataFrame to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0b06298-1736-471c-b876-3f5dae094713",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark_df.withColumn(\"NETAMOUNT\",spark_df['NETAMOUNT'].cast('double'))\n",
    "spark_df = spark_df.withColumn(\"PartnerRevenue\",spark_df['PartnerRevenue'].cast('double'))\n",
    "dataframe=spark_df.toPandas()\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa3888e8-e3e2-48b7-82aa-4f14994a6d27",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1.4 Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01d0f212-4a1a-4623-acd8-ee8dd1d04069",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 1.4.1 Replace the zero values with the mean values in few of the selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ec94fcf-e80e-4074-9124-1751391e0b9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataframe=dataframe.replace({'NETAMOUNT': {0: dataframe['NETAMOUNT'].mean(skipna=True)}})\n",
    "dataframe=dataframe.replace({'PartnerRevenue': {0: dataframe['PartnerRevenue'].mean(skipna=True)}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f3151c6-ff76-4227-9931-e300ecaf639d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 1.4.2 Perform One Hot Encoding on the Categorical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "babf9c32-ea40-4a09-a1e3-dfd355ba6ec2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Note that if you use a lower version of sklearn, you will have to replace get_feature_names_out() with get_feature_names() in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efb8a1d1-dc13-47a5-bcb5-e64e5db15378",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def one_hot_encode(df,column):\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    encoder_df = pd.DataFrame(encoder.fit_transform(df[[column]]).toarray())\n",
    "    encoded_columns = encoder.get_feature_names_out([column])\n",
    "    encoder_df.columns = encoded_columns\n",
    "    return encoder_df,encoded_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "680419aa-6534-442f-a879-51a996e6260c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "encoded_column_names=[]\n",
    "for column in ['Customer','Customer Name','First Name','Last Name','Promocode','City','State','Currency','SALESORGANIZATION','MATERIAL','MATERIALGROUP','PURCHASEORDERBYCUSTOMER','TRANSACTIONCURRENCY','SALESDOCUMENTDATE']:\n",
    "    encoded_df, encoded_columns = one_hot_encode(dataframe, column)\n",
    "    dataframe = dataframe.join(encoded_df, rsuffix='_'+column)\n",
    "    encoded_column_names += encoded_columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe2adcf7-54c0-496d-b57a-23f09a72f254",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 2. Now, using the data,  train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bf72530-5039-468b-9383-494276574fdc",
     "showTitle": false,
     "title": ""
    },
    "gather": {
     "logged": 1633630693823
    }
   },
   "outputs": [],
   "source": [
    "import os,json\n",
    "import pandas as pd\n",
    "import mlflow \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label_column = 'PartnerRevenue'\n",
    "y = dataframe[label_column]\n",
    "dataframe.drop(label_column, axis=1, inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataframe , y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "770444c7-ae63-4d21-895f-5431f012295f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.1 Use the columns required for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc60fcdf-68b5-4cba-b971-ea8eb0850c5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_columns=['NETAMOUNT']+encoded_column_names\n",
    "X_train_dataframe,X_test_dataframe=X_train[train_columns],X_test[train_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1afed97a-62c2-40a1-ac9e-297687be59da",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2.2 Train the model and log results using mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30036187-acc5-4ccf-a1ee-e4061aee03be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_model(X_train,X_test, y_train, y_test,experiment_name,model_name):\n",
    "    mlflow.set_experiment(experiment_name) \n",
    "    print(\"Training model...\")\n",
    "\n",
    "    #Train the LinearRegression model using the fit method\n",
    "    with mlflow.start_run() as run:\n",
    "        model = LinearRegression().fit(X_train_dataframe, y_train)\n",
    "        score = model.score(X_test_dataframe, y_test)\n",
    "        mlflow.log_param(\"score\",score)\n",
    "        mlflow.sklearn.log_model(model,model_name,\n",
    "                         registered_model_name = model_name)\n",
    "        \n",
    "    run_id = run.info.run_id\n",
    "    return run_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aebc3108-5623-4cb7-ad9e-21620636884a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Replace the user with the appropriate databricks user in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc8bc493-5ab0-40ba-8723-65180de67ba9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "experiment_name,model_name='/Users/jerome.ivain@databricks.com/PartnerRevenuePredictionExperiment','PartnerRevenuePredictionModel'\n",
    "run_id=train_model(X_train,X_test, y_train, y_test,experiment_name,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a053805b-8b3b-45a2-9bdd-7fa85cfa2325",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uri=f\"runs:/{run_id}/{model_name}\"\n",
    "print(\"The MODEL_URI is '{}'\".format(model_uri))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1210397-78e4-4d98-83d9-1df7aaa66ade",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 3. Register the  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7859ab7a-e53e-48bc-80f5-daab48f1d666",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "model_version = mlflow.register_model(model_uri=model_uri,name=model_name)\n",
    " \n",
    "# Registering the model takes a few seconds, so add a small delay\n",
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2554de8c-a6c2-4a79-8fa1-4375d2dba28b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 4. Transition the model to production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb23b7ff-72bc-4996-b77e-59f51d2c7ecf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    " \n",
    "client = MlflowClient()\n",
    "client.transition_model_version_stage(\n",
    "  name=model_name,\n",
    "  version=model_version.version,\n",
    "  stage=\"Production\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fbabeb1-2f03-4343-b01b-dbd770660a30",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5. Inference the deployed model by passing the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a7e72f3-1777-42a3-bfa2-5fbbdaabc6e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#X_test_dataframe['NETAMOUNT'] = X_test_dataframe['NETAMOUNT'].astype(float)\n",
    "#X_test_dataframe['PartnerRevenue'] = X_test_dataframe['PartnerRevenue'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85b82f03-05d6-417a-bff3-47492713fcfe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model = mlflow.pyfunc.load_model(f\"models:/{model_name}/production\")\n",
    "result=model.predict(X_test_dataframe)\n",
    "inference_dataframe=pd.DataFrame(result,columns=['prediction_result'])\n",
    "inference_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8f24f2b-8a91-49ea-9d20-ac405d7d1dc2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6. Store the inferencing result in SAP Datasphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cca16d03-e0b7-404a-b472-a13f6c82edda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.1 Store the inference result in the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "617b05e2-cd5b-41c2-805a-581cf2c591cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test['Predicted_PartnerRevenue']=inference_dataframe['prediction_result'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0319516-8b42-438e-88a1-97a2e6a27240",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.2 Select the required columns from pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29285ccf-00f6-4233-bcad-0223197331b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ad1baf3-9104-4525-a40f-828594ecda69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasphere_write_dataframe=X_test[['SALESORGANIZATION','MATERIAL','MATERIALGROUP','PURCHASEORDERBYCUSTOMER', 'TRANSACTIONCURRENCY','NETAMOUNT','Customer','Customer Name','First Name','Last Name','Promocode','City','State','Currency','SALESDOCUMENTDATE','Year', 'Predicted_PartnerRevenue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4c3bffd-67fd-4ee0-b6f8-c48f3d11c2d9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.3 Renaming the columns in the pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "695a80f7-abf1-48b0-be5d-9a765c27b63b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasphere_write_dataframe.rename(columns = {'Customer Name':'Customer_Name', 'First Name':'First_Name', 'Last Name':'Last_Name'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "293962c6-67a0-43a0-89d7-7abd10512019",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "datasphere_write_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcd07cbf-4ce5-4e91-9a6b-05348020244d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.4 Create a table in SAP Datasphere for storing the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ab56f5-27f2-4607-b2d7-ebbeb6a80b13",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "db.drop_table(\"SALES_TABLE\")\n",
    "\n",
    "db.create_table(\"CREATE TABLE SALES_TABLE (SALESORGANIZATION Varchar(20),MATERIAL Varchar(20),MATERIALGROUP Varchar(20),PURCHASEORDERBYCUSTOMER Varchar(20),TRANSACTIONCURRENCY Varchar(20),NETAMOUNT Float,Customer Varchar(20), Customer_Name Varchar(50),First_Name Varchar(20),Last_Name Varchar(20),Promocode Varchar(20),City Varchar(20),State Varchar(20),PartnerRevenue Float,Currency Varchar(20),SALESDOCUMENTDATE Varchar(20),Year Varchar(20),Predicted_PartnerRevenue Float)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71fd235b-f428-4b66-956c-b2d62eeb126b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.5 Write the prediction results to 'SALES_TABLE' table in SAP Datasphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85cc93d9-dd28-43fd-b6d5-6122a3b0ef16",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "db.insert_into_table('SALES_TABLE',datasphere_write_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c272a40-a88a-46bd-ba73-48cb746c0d89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tables=db.get_table_metadata('SALES_TABLE')\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "893200e7-bb80-4bd9-aa82-8d7b8dc94ea6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7. Store in the DELTA LAKE as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2486e3ed-3fb8-4421-a0c9-159beed31e75",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 7.1 Create the 'SALES_TABLE' table with the new predicted field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f241c2e-9928-41be-931d-5526554233a5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema_name = \"dbdemos_jerome.sap\"\n",
    "table_name = \"dbdemos_jerome.sap.SAP_SALES_PREDICTED\"\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_name}\")\n",
    "spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "dsp_spark_df=spark.createDataFrame(datasphere_write_dataframe) \n",
    "dsp_spark_df.write.format(\"delta\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a5c2fad2-6b87-47af-baa2-2601d99a8c6d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 7.2 Generate Audible Ready Descriptions for MATERIALGROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6efe035-71fa-4c6b-a44e-11d3adc289ee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "CREATE TABLE dbdemos_jerome.sap.MAT_DESC AS SELECT MATERIALGROUP, ai_gen(\"Describe in one sentence this material column value:\"||MATERIALGROUP) as Material_Desc FROM dbdemos_jerome.sap.SAP_SALES_PREDICTED GROUP BY MATERIALGROUP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcdee609-7d54-48a1-ab64-a4c10341cd61",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tbl_location = spark.sql(f\"DESCRIBE DETAIL {table_name}\").first().location\n",
    "print(tbl_location)\n",
    "\n",
    "files = dbutils.fs.ls(tbl_location)\n",
    "display(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f6e0dfa-7060-4aeb-bd4a-0bdc7d773ddc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df=spark.sql('SELECT SalesOrganization, AVG(Predicted_PartnerRevenue) FROM dbdemos_jerome.sap.SAP_SALES_PREDICTED group by SALESORGANIZATION')\n",
    "spark_df.display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2995129009141603,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "SAP Datasphere-FedML-Databricks-Integration-With-Deployment-to-Databricks",
   "widgets": {}
  },
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('3.8.11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7f76e95e30fdba57d4abc13ceb61999061460bba7ad6964f813125e33379908"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
